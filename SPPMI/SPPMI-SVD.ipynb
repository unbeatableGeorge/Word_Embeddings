{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:13:13.681727Z",
     "start_time": "2025-08-27T06:13:12.098424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# ==== SPPMI-SVD: runnable, self-contained ====\n",
    "\n",
    "\n",
    "# 1) 准备数据：加载 text8\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "USE_TOY = False  # True: 用内置玩具数据；False: 读取本地语料文件\n",
    "\n",
    "save_dir = \"./models_sppmi\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "if USE_TOY:\n",
    "    # 已分词的小数据（演示）\n",
    "    sentences = [\n",
    "        [\"I\", \"love\", \"natural\", \"language\", \"processing\"],\n",
    "        [\"word2vec\", \"is\", \"a\", \"popular\", \"model\", \"for\", \"embeddings\"],\n",
    "        [\"we\", \"can\", \"learn\", \"word\", \"relationships\"],\n",
    "        [\"word\", \"embeddings\", \"capture\", \"semantic\", \"meanings\"],\n",
    "        [\"I\", \"enjoy\", \"teaching\", \"word2vec\", \"to\", \"students\"]\n",
    "    ]\n",
    "else:\n",
    "    # 这是一个迭代器，产出的是一串词（没有真正的句子边界）\n",
    "    text8 = api.load(\"text8\")  # 第一次会自动下载到本地缓存\n",
    "    # text8 是类似 [\"anarchism\", \"originated\", \"as\", ...] 的token流\n",
    "\n",
    "    # 可选：为了方便共现窗口，你可以把它切成伪句子（比如每2k个词一段）\n",
    "    def make_sentences(tokens, sent_len=2048):\n",
    "        buf, cnt = [], 0\n",
    "        for w in tokens:\n",
    "            buf.append(w)\n",
    "            cnt += 1\n",
    "            if cnt >= sent_len:\n",
    "                yield buf\n",
    "                buf, cnt = [], 0\n",
    "        if buf:\n",
    "            yield buf\n",
    "\n",
    "    sentences = list(make_sentences(text8, sent_len=2048))[0]  # 注意：会占用内存，想省内存就边流式边处理\n",
    "\n",
    "len(sentences), len(sentences[0][:10])"
   ],
   "id": "32901cf3ac70c771",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:13:18.673265Z",
     "start_time": "2025-08-27T06:13:16.743626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "# -----------------------------\n",
    "# 2) 参数\n",
    "# -----------------------------\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "from scipy.sparse import coo_matrix, save_npz, load_npz\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import coo_matrix, save_npz, load_npz\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "min_count = 1        # 频次阈值，调大可省内存\n",
    "shift_k     = 5       # SPPMI 的 k（通常与负采样 k 对应）\n",
    "window_sizes = [4, 6, 8]        # 共现窗口（左右各 window_size）\n",
    "embed_dims   = [100, 200]       # 词向量维度（SVD 维度）\n",
    "\n",
    "\n",
    "# 2) 构建词表（限制词表规模，避免内存过大）\n",
    "max_vocab = 50000     # 也可用 top-K 限制\n",
    "V = 50000\n",
    "cnt = Counter(w.lower() for s in sentences for w in s)\n",
    "\n",
    "# 过滤 & 截断\n",
    "vocab_words = [w for w,c in cnt.items() if c >= min_count]\n",
    "vocab_words = sorted(vocab_words, key=lambda w: cnt[w], reverse=True)[:max_vocab]\n",
    "\n",
    "vocab = {w:i for i,w in enumerate(vocab_words)}\n",
    "id2word = {i:w for w,i in vocab.items()}\n",
    "\n",
    "with open(\"id2word.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(id2word, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 3) 共现统计（对称窗口）\n",
    "\n",
    "def co_statistics(win, dim, USE_LOCAL_CO = True):\n",
    "\n",
    "    fname = os.path.join(save_dir, f\"CO_win{win}_dim{dim}.npz\")\n",
    "\n",
    "    if not USE_LOCAL_CO:\n",
    "        co_counts = defaultdict(float)\n",
    "        total_tokens = 0\n",
    "        for sent in sentences:\n",
    "            tokens = [w.lower() for w in sent if w.lower() in vocab]\n",
    "            n = len(tokens)\n",
    "            total_tokens += n\n",
    "            for i, w in enumerate(tokens):\n",
    "                wi = vocab[w]\n",
    "                start = max(0, i - win)\n",
    "                end   = min(n, i + win + 1)\n",
    "                for j in range(start, end):\n",
    "                    if j == i:\n",
    "                        continue\n",
    "                    c = tokens[j]\n",
    "                    if c not in vocab:\n",
    "                        continue\n",
    "                    wj = vocab[c]\n",
    "                    co_counts[(wi, wj)] += 1.0\n",
    "        if not co_counts:\n",
    "            raise ValueError(\"Co-occurrence counts are empty. Increase data/window or lower min_count.\")\n",
    "\n",
    "        # 稀疏矩阵\n",
    "        V = max_vocab\n",
    "        r, c, v = zip(*[(i,j,x) for (i,j),x in co_counts.items()])\n",
    "        CO = coo_matrix((v, (r, c)), shape=(V, V), dtype=np.float64).tocsr()\n",
    "        save_npz(fname, CO)\n",
    "    else:\n",
    "        CO = load_npz(fname)\n",
    "\n",
    "    return CO\n",
    "\n",
    "\n",
    "\n",
    "def SPPMI_calculation(win, dim, CO, USE_LOCAL_SPPMI = True):\n",
    "    # 4) 从 CO 计算 SPPMI\n",
    "\n",
    "    fname = os.path.join(save_dir, f\"SPPMI_win{win}_dim{dim}.npz\")\n",
    "\n",
    "    if not USE_LOCAL_SPPMI:\n",
    "        sum_co = CO.sum()\n",
    "        pi = np.array(CO.sum(axis=1)).ravel() / sum_co\n",
    "        pj = np.array(CO.sum(axis=0)).ravel() / sum_co\n",
    "\n",
    "        CO_coo = CO.tocoo()\n",
    "        spmi_data = []\n",
    "        shift_k = 5.0  # 可调\n",
    "\n",
    "        for i, j, x in zip(CO_coo.row, CO_coo.col, CO_coo.data):\n",
    "            pij = x / sum_co\n",
    "            denom = pi[i] * pj[j]\n",
    "            if denom == 0 or pij == 0:\n",
    "                continue\n",
    "            pmi = math.log(pij / denom)\n",
    "            val = max(pmi - math.log(shift_k), 0.0)  # SPPMI\n",
    "            if val > 0:\n",
    "                spmi_data.append((i, j, val))\n",
    "\n",
    "        if not spmi_data:\n",
    "            raise ValueError(\"SPPMI is empty. Try a smaller k, larger window, or larger vocab.\")\n",
    "\n",
    "        ri, rj, rv = zip(*spmi_data)\n",
    "        SPPMI = coo_matrix((rv, (ri, rj)), shape=(V, V), dtype=np.float64).tocsr()\n",
    "        save_npz(fname, SPPMI)\n",
    "    else:\n",
    "        SPPMI = load_npz(fname)\n",
    "    return SPPMI\n",
    "\n",
    "\n",
    "def embedding_matrix(win, dim, SPPMI, USE_LOCAL_EMB = True):\n",
    "    # 5) SVD 得到词向量 + 相似词查询\n",
    "\n",
    "    fname = os.path.join(save_dir, f\"emb_win{win}_dim{dim}.npy\")\n",
    "\n",
    "    if not USE_LOCAL_EMB:\n",
    "        svd = TruncatedSVD(n_components=min(dim, max(2, min(SPPMI.shape)-1)), random_state=42)\n",
    "        U = svd.fit_transform(SPPMI)  # (V, d)\n",
    "\n",
    "        Sigma_sqrt = np.sqrt(svd.singular_values_)\n",
    "        emb = U * Sigma_sqrt\n",
    "        emb = normalize(emb)\n",
    "        np.save(fname, emb)\n",
    "    else:\n",
    "        emb = np.load(fname)\n",
    "\n",
    "    return emb"
   ],
   "id": "2b552bb93e93678d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T07:36:59.033902Z",
     "start_time": "2025-08-27T07:36:52.116442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "for win, dim in itertools.product(window_sizes, embed_dims):\n",
    "    print(f\"\\n[INFO] Running with window={win}, dim={dim}\")\n",
    "\n",
    "    # 1) 共现矩阵\n",
    "    CO = co_statistics(win, dim, USE_LOCAL_CO=True)\n",
    "\n",
    "    # 2) SPPMI\n",
    "    SPPMI = SPPMI_calculation(win, dim, CO, USE_LOCAL_SPPMI=True)\n",
    "\n",
    "    # 3) Embedding\n",
    "    emb = embedding_matrix(win, dim, SPPMI, USE_LOCAL_EMB=True)\n",
    "\n",
    "    # 4) Top-4 最近邻查询\n",
    "    word = \"science\"\n",
    "    if word in vocab:\n",
    "        qv = emb[vocab[word]]\n",
    "        sims = emb @ qv\n",
    "        idx = np.argpartition(-sims, range(5))[:5]  # 取前5（包含自己）\n",
    "        idx = idx[np.argsort(-sims[idx])]\n",
    "        print(f\"\\nTop-4 nearest neighbors of '{word}' (win={win}, dim={dim}):\")\n",
    "        count = 0\n",
    "        for i in idx:\n",
    "            if id2word[i] == word:\n",
    "                continue\n",
    "            print(f\"   {id2word[i]:>12s}  {sims[i]:.4f}\")\n",
    "            count += 1\n",
    "            if count >= 4:\n",
    "                break\n",
    "    else:\n",
    "        print(\"[WARN] word not in vocabulary.\")\n"
   ],
   "id": "91330b9d2d023a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running with window=4, dim=100\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=4, dim=100):\n",
      "          study  0.8829\n",
      "        studies  0.8790\n",
      "       research  0.8766\n",
      "     scientific  0.8736\n",
      "\n",
      "[INFO] Running with window=4, dim=200\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=4, dim=200):\n",
      "     scientific  0.8398\n",
      "          study  0.8395\n",
      "        studies  0.8302\n",
      "       research  0.8286\n",
      "\n",
      "[INFO] Running with window=6, dim=100\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=6, dim=100):\n",
      "       research  0.8779\n",
      "     scientific  0.8776\n",
      "          study  0.8735\n",
      "        journal  0.8719\n",
      "\n",
      "[INFO] Running with window=6, dim=200\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=6, dim=200):\n",
      "     scientific  0.8402\n",
      "        journal  0.8388\n",
      "       research  0.8370\n",
      "          study  0.8343\n",
      "\n",
      "[INFO] Running with window=8, dim=100\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=8, dim=100):\n",
      "     scientific  0.8905\n",
      "        journal  0.8856\n",
      "       research  0.8819\n",
      "          study  0.8814\n",
      "\n",
      "[INFO] Running with window=8, dim=200\n",
      "\n",
      "Top-4 nearest neighbors of 'science' (win=8, dim=200):\n",
      "     scientific  0.8546\n",
      "        journal  0.8509\n",
      "       research  0.8442\n",
      "          study  0.8432\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "392ac49863636367"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
