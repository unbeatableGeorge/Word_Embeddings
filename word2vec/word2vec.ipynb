{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T13:03:17.875225Z",
     "start_time": "2025-08-26T13:03:16.456253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 1 (enhanced)\n",
    "# Import necessary libraries\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from pprint import pprint\n",
    "\n",
    "# ---------- Step 1: Load a larger dataset ----------\n",
    "print(\"[INFO] Loading dataset: text8 (≈17MB Wikipedia subset)\")\n",
    "dataset = api.load(\"text8\")   # 一个约17M的维基百科子集\n",
    "# 切成句子块（gensim 需要 list of list）\n",
    "def make_sentences(tokens, sent_len=2048):\n",
    "    buf, cnt = [], 0\n",
    "    for w in tokens:\n",
    "        buf.append(w)\n",
    "        cnt += 1\n",
    "        if cnt >= sent_len:\n",
    "            yield buf\n",
    "            buf, cnt = [], 0\n",
    "    if buf:\n",
    "        yield buf\n",
    "\n",
    "sentences = list(make_sentences(dataset, sent_len=2048))[0]"
   ],
   "id": "426782fe11c11b30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset: text8 (≈17MB Wikipedia subset)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T13:16:51.350811Z",
     "start_time": "2025-08-26T13:03:18.627534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import itertools\n",
    "# ---------- Step 2: Train a Word2Vec model ----------\n",
    "\n",
    "# 超参数组合\n",
    "window_sizes = [4, 6, 8]\n",
    "embed_dims   = [100, 200]\n",
    "\n",
    "# 保存目录\n",
    "save_dir = \"./models_word2vec\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 网格搜索\n",
    "for win, dim in itertools.product(window_sizes, embed_dims):\n",
    "    params = dict(vector_size=dim, window=win, min_count=5, sg=1, workers=4)\n",
    "    print(f\"[INFO] Training Word2Vec with window={win}, dim={dim}\")\n",
    "    model = Word2Vec(sentences, **params)\n",
    "\n",
    "    # 文件名区分不同组合\n",
    "    fname = os.path.join(save_dir, f\"word2vec_win{win}_dim{dim}.model\")\n",
    "    model.save(fname)\n",
    "    print(f\"[SAVE] {fname}\")"
   ],
   "id": "f8567c6b5e938b45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Word2Vec with window=4, dim=100\n",
      "[SAVE] ./models_word2vec/word2vec_win4_dim100.model\n",
      "[INFO] Training Word2Vec with window=4, dim=200\n",
      "[SAVE] ./models_word2vec/word2vec_win4_dim200.model\n",
      "[INFO] Training Word2Vec with window=6, dim=100\n",
      "[SAVE] ./models_word2vec/word2vec_win6_dim100.model\n",
      "[INFO] Training Word2Vec with window=6, dim=200\n",
      "[SAVE] ./models_word2vec/word2vec_win6_dim200.model\n",
      "[INFO] Training Word2Vec with window=8, dim=100\n",
      "[SAVE] ./models_word2vec/word2vec_win8_dim100.model\n",
      "[INFO] Training Word2Vec with window=8, dim=200\n",
      "[SAVE] ./models_word2vec/word2vec_win8_dim200.model\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T13:20:19.555401Z",
     "start_time": "2025-08-26T13:20:19.317361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- Step 3: Explore the Word2Vec model ----------\n",
    "\n",
    "win = 4     # 4/6/8\n",
    "dim = 100   # 100/200\n",
    "\n",
    "path = os.path.join(save_dir, f\"word2vec_win{win}_dim{dim}.model\")\n",
    "model = Word2Vec.load(path)\n",
    "print(\"\\n[INFO] Vocabulary size:\", len(model.wv))\n",
    "print(\"[INFO] Top-20 most frequent tokens:\")\n",
    "pprint(model.wv.index_to_key[:20])"
   ],
   "id": "c10ca6b356d3cc37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Vocabulary size: 71290\n",
      "[INFO] Top-20 most frequent tokens:\n",
      "['the',\n",
      " 'of',\n",
      " 'and',\n",
      " 'one',\n",
      " 'in',\n",
      " 'a',\n",
      " 'to',\n",
      " 'zero',\n",
      " 'nine',\n",
      " 'two',\n",
      " 'is',\n",
      " 'as',\n",
      " 'eight',\n",
      " 'for',\n",
      " 's',\n",
      " 'five',\n",
      " 'three',\n",
      " 'was',\n",
      " 'by',\n",
      " 'that']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T13:20:36.499178Z",
     "start_time": "2025-08-26T13:20:36.494351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- Step 4: Safe vector lookup ----------\n",
    "def safe_vec(w):\n",
    "    if w in model.wv:\n",
    "        print(f\"\\n[OK] Vector for '{w}': shape={model.wv[w].shape}\")\n",
    "        print(model.wv[w])\n",
    "    else:\n",
    "        print(f\"\\n[WARN] '{w}' not in vocabulary (OOV). Try another word.\")\n",
    "# 你原本用 'Word\n",
    "# 2Vec' 这个词，但在 text8 里几乎不可能出现，容易 OOV\n",
    "safe_vec(\"language\")     # 在 text8 中基本一定存在"
   ],
   "id": "fa301ace0f630f09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Vector for 'language': shape=(100,)\n",
      "[-5.63780665e-01 -1.43342018e-01 -1.93605721e-01  5.01701832e-02\n",
      "  3.68403435e-01  1.69639453e-01  4.76629049e-01  2.73675889e-01\n",
      " -6.46183074e-01 -1.00742295e-01 -3.78163218e-01  1.89057052e-01\n",
      " -6.51260853e-01  7.71197602e-02 -2.48700157e-02 -1.76573202e-01\n",
      "  1.03793316e-01 -4.54686470e-02  4.56223696e-01 -1.94364607e-01\n",
      "  9.44484547e-02 -6.38125837e-01 -3.12224925e-02 -2.82439440e-01\n",
      " -4.39857006e-01 -2.64926553e-02 -1.51290402e-01 -1.51182428e-01\n",
      " -2.04791531e-01 -1.30243093e-01 -3.66244942e-01 -4.15785983e-03\n",
      "  5.57571888e-01 -9.31952074e-02 -8.81810784e-02  4.43528026e-01\n",
      " -2.47798681e-01  1.30837619e-01  9.93213733e-04 -1.66155040e-01\n",
      " -2.56508291e-01 -1.27962202e-01 -8.27650949e-02 -8.22350234e-02\n",
      " -3.64964336e-01 -4.02844667e-01  1.84474811e-01  1.51095107e-01\n",
      "  8.68820429e-01  5.69558069e-02  2.24656343e-01  2.09192812e-01\n",
      " -1.06547043e-01 -4.16797876e-01 -4.21094030e-01 -3.47633153e-01\n",
      "  3.10274929e-01 -2.74279341e-02  1.94999631e-02  3.06548059e-01\n",
      " -6.69655383e-01 -1.78151373e-02  8.27361286e-01  1.71702474e-01\n",
      " -3.17407012e-01  6.02065563e-01  1.01942241e+00  4.13135916e-01\n",
      "  9.27842222e-04  4.77629043e-02 -6.33252710e-02  4.26750481e-01\n",
      "  8.10678676e-02  7.47007281e-02  6.25887573e-01  5.61429262e-01\n",
      "  2.60670662e-01  1.83633357e-01 -5.94117530e-02  2.67526180e-01\n",
      " -3.28998059e-01  5.89995503e-01 -3.58666122e-01  2.99675196e-01\n",
      "  5.66154182e-01  1.91832826e-01 -1.19669229e-01  6.31158113e-01\n",
      "  2.18403175e-01  3.60627383e-01 -5.39976582e-02  5.00740707e-01\n",
      "  1.59615144e-01  2.63701379e-01  7.08977163e-01  3.22780371e-01\n",
      " -3.42754498e-02 -5.97291648e-01 -3.41311634e-01  1.61954075e-01]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1984ae10ac1ff966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
